{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De início, realizei uma análise no arquivo excel, e fiz uma série de pré-processamentos direto no arquivo.\n\n1) Das 5644 linhas, exclui todas as que tinham todas as colunas de atributos (variáveis independentes ou features) sem valores. A base foi reduzida a 623 linhas.\n\n2) Em seguida, excluí todas as colunas de atributos que não tinham valor para nenhuma linha, e (por enquanto) também as colunas categóricas. A base foi reduzida a 68 colunas.\n\n3) Coluna \"SARS-Cov-2 exam result\" teve os valores alterados : \"negative\" --> 0, \"positive\"--> 1. São 87 positivos na base reduzida.\n\n4) Portanto, ficamos com as colunas: SARS-Cov-2 exam result,\tPatient addmited to regular ward, Patient addmited to semi-intensive unit, e Patient addmited to intensive care unit como labels (variáveis dependentes). Nesta primeira análise somente a primeira será utilizada.\n\n5) As demais colunas serão os atributos. Patient ID não será utilizado.\n\n6) Células vazias (nan) foram preenchidas com zero\n\n"},{"metadata":{},"cell_type":"markdown","source":"### Carga do novo arquivo reduzido"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_red = pd.read_excel('/kaggle/input/newfile/dataset_modificado.xlsx', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_red","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_red.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_red.describe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Duas análises são necessárias:\n\n1) a previsão de diagnóstico positivo/negativo para o vírus (coluna SARS-Cov-2 exam result). Aqui temos como saída apenas uma coluna categórica.\n\n2) a previsão de qual será o encaminhamento para o paciente (colunas Patient addmited to regular ward, Patient addmited to semi-intensive unit, e Patient addmited to intensive care unit). Aqui, então, temos 3 colunas categóricas.\n\n3) o modelo de classificação escolhido foi o de ÁRVORES DE DECISÃO, depois comparado com FLORESTAS ALEATÓRIAS"},{"metadata":{},"cell_type":"markdown","source":"# ANÁLISE DE PREVISÃO DE DIAGNÓSTICO"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Divisão da massa de dados em pacientes (linhas) de TREINAMENTO e TESTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dividir_treino_teste(data, perc_treinamento):\n  np.random.seed(0)\n  #np.random.shuffle(data)\n  divisao = int(data.shape[0] * perc_treinamento)\n  conj_treinamento = data[:divisao]\n  conj_teste = data[divisao:]\n  \n  return conj_treinamento,conj_teste","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Divisão das colunas em atributos (variáveis independentes) e labels (rótulos, variável dependente). Também **normaliza** os atributos."},{"metadata":{"trusted":true},"cell_type":"code","source":"def gerar_atributos_labels(data):\n  \n  labels = data['SARS-Cov-2 exam result']\n\n  atributos = data.iloc[:,5:]\n\n  atributos= preprocessing.StandardScaler().fit(atributos).transform(atributos)\n\n  return atributos, labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ÁRVORE DE DECISÃO"},{"metadata":{},"cell_type":"markdown","source":"Criação do modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"def decision_tree_previsto_real(data):\n    \n  # dividir o conjunto de dados em treinamento (70%) e teste\n  pac_treinamento, pac_teste = dividir_treino_teste(data, 0.7)\n\n  # gerar os conjuntos de atributos e labels para treinamento e testes\n  atributos_treinamento, labels_treinamento = gerar_atributos_labels(pac_treinamento)\n  atributos_teste, labels_teste = gerar_atributos_labels(pac_teste)\n\n  # cria uma instância de classificador por árvore de decisão\n  dtr = DecisionTreeClassifier()\n\n  # treina o classificador com os pacientes de treinamento\n  dtr.fit(atributos_treinamento,labels_treinamento)\n\n  # obtém previsões para os atributos de teste\n  previsoes = dtr.predict(atributos_teste)\n\n  # retorna as previsões e os labels teste (reais)\n  return previsoes,labels_teste\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Análise da saída do modelo gerado"},{"metadata":{"trusted":true},"cell_type":"code","source":"classe_prevista, classe_real = decision_tree_previsto_real(ds_red)\n\n# mostra os 10 primeiros resultados\nprint(\"Alguns resultados iniciais...\\n   previsto,  real\")\nfor i in range(10):\n    print(\"{}. {}, {}\".format(i, classe_prevista[i], classe_real[i]))\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.tree import DecisionTreeClassifier\n#from support_functions import plot_confusion_matrix\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cálculo da precisão (accuracy) do modelo, e matriz de confusão"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implement the following function\ndef calcula_precisao(previsto, real):\n  previsoes = 0\n  previsoes_corretas = 0\n  for i in range(len(previsto)):\n    previsoes += 1\n    if(previsto[i] == real[i]):\n      previsoes_corretas += 1\n  return (previsoes_corretas / previsoes)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the data\natributos, labels = gerar_atributos_labels(ds_red)\n\n# train the model to get predicted and actual classes\ndtc = DecisionTreeClassifier()\nprevisto = cross_val_predict(dtc, atributos, labels, cv=10)\n\n# calculate the model score using your function\nmodel_score = calcula_precisao(previsto, labels)\nprint(\"Score de precisão:\", model_score)\n\n# calculate the models confusion matrix using sklearns confusion_matrix function\nclass_labels = list(set(labels))\nmodel_cm = confusion_matrix(y_true=labels, y_pred=previsto, labels=class_labels)\n\nmodel_cm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FLORESTA ALEATÓRIA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier\n\n\ndef random_forest_previsto_real(data, n_estimators):\n  \n  # gerar atributos e labels\n  atributos, labels = gerar_atributos_labels(data)\n\n  # instanciar um classificador por floresta aleatória\n  rfc = RandomForestClassifier(n_estimators=n_estimators)\n  \n  # obtem previsoes usando 10-fold cross validation\n  previsto = cross_val_predict(rfc,atributos,labels,cv=10)\n\n  # retorna valores previstos e reais\n  return previsto,labels\n\n\n# get the predicted and actual classes\nnum_arvores = 50              \nprevisto, real = random_forest_previsto_real(ds_red, num_arvores)\n\n# calculate the model score using your function\nprecisao = calcula_precisao(previsto, real)\nprint(\"Score de precisão:\", precisao)\n\n# calculate the models confusion matrix using sklearns confusion_matrix function\nclass_labels = list(set(real))\nmodel_cm = confusion_matrix(y_true=real, y_pred=previsto, labels=class_labels)\n\nmodel_cm\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Portanto, dos dois modelos acima, o de floresta aleatória chega a uma melhor precisão para diagnóstico positivo/negativo."},{"metadata":{},"cell_type":"markdown","source":"# ANÁLISE DE ENCAMINHAMENTO"},{"metadata":{},"cell_type":"markdown","source":"Para esta análise, foi gerada uma cópia do dataset utilizado acima, onde as colunas: \"Patient addmited to regular ward\", \"Patient addmited to semi-intensive unit\", e \"Patient addmited to intensive care unit\" foram substituídas pela coluna \"encaminhamento\", que possui os valores : \n\nRW --> Se \"Patient addmited to regular ward\" = 1\n\nSIU --> Se \"Patient addmited to semi-intensive unit\" = 1\n\nICU --> Se \"Patient addmited to intensive care unit\" = 1\n\nNONE --> Se as três colunas acima = 0\n\nAs demais colunas permanecem as mesmas utilizadas na análise inicial.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_enc = pd.read_excel('/kaggle/input/classif/dataset_classif.xlsx', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_enc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_enc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_enc['encaminhamento'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Abaixo uma breve análise gráfica de um atributo exemplo (Hematocrit) observado versus o quantil de idade, mostrando o agrupamento por encaminhamento. É possível ver que os encaminhamentos realizados (diferentes de NONE) concentram-se nas faixas de idade iniciais (bebês e recém nascidos) e idosos."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nbins = np.linspace(ds_enc.Hematocrit.min(), ds_enc.Hematocrit.max(), 10)\ng = sns.FacetGrid(ds_enc, col=\"Patient age quantile\", hue=\"encaminhamento\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Hematocrit', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seleção dos labels e atributos, seguindo o mesmo critério acima."},{"metadata":{"trusted":true},"cell_type":"code","source":"atributos = ds_enc.iloc[:,3:]\n\nX = atributos\ny = ds_enc['encaminhamento'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalização dos atributos"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classificação"},{"metadata":{},"cell_type":"markdown","source":"Para a classificação, utilizarei a técnica de clusterização - K Nearest Neighbor(KNN). \nVou manter os nomes em inglês pois trata-se de código que eu já havia desenvolvido em treinamento.\n\nEm seguida compararei com outras técnicas para ver qual tem a melhor precisão - \n\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"## KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=4) #mantendo proporção de treinamento em 70%\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Iniciarei com 3 clusters; abaixo testaremos a precisão para escolher um valor melhor."},{"metadata":{"trusted":true},"cell_type":"code","source":"k = 3 \n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = neigh.predict(X_test)\nyhat[0:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aqui escolheremos o melhor valor (melhor precisão) para o número de clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"lim=25\navg=np.zeros((lim-1))\nstdd=np.zeros((lim-1))\ncm=[];\nmaxacc = 0;\nbestk = 0;\nfor k in range(1,lim):\n    \n    #Train Model and Predict  \n    kNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n    yhat = kNN_model.predict(X_test)\n    avg[k-1]=np.mean(yhat==y_test);\n    stdd[k-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n    \n    print(\"k = \",k,\"*** accuracy = \",avg[k-1] )\n    \n    if avg[k-1] > maxacc:\n        bestk = k \n        maxacc = avg[k-1]\n   \nprint(\"The best value of k (best accuracy) is: \",bestk)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Construir novamente o modelo, usando k = 4 para melhor precisão, como obtido acima"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the model again, using the k=7 with best accuracy\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 4\n#Train Model and Predict  \nkNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\nkNN_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = kNN_model.predict(X_test)\nyhat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4) #profundidade arbitrária por enquanto\ndt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat1 = dt.predict(X_test)\nyhat1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calcular a precisão :"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg=np.mean(yhat1==y_test);\nprint(\"*** accuracy = \",avg )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nmodsvm = svm.SVC()\nmodsvm.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat2 = modsvm.predict(X_test)\nyhat2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calcular a precisão :"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg=np.mean(yhat2==y_test);\nprint(\"*** accuracy = \",avg )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(C=0.01).fit(X_train,y_train)\nLR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat3 = LR.predict(X_test)\nyhat3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg=np.mean(yhat3==y_test);\nprint(\"*** accuracy = \",avg )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Portanto o modelo KNN é o que oferece a melhor precisão."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}